---
title: "Farnsworth Thesis Code"
output: html_document
date: "2025-04-28"
---

```{r}
library(readxl)
library(dplyr)
library(tidyr)
library(lubridate)
library(quadprog)
library(ggplot2)
library(knitr)
library(kableExtra)
library(showtext)
library(zoo)
library(sysfonts)
library(future)
library(future.apply)
library(patchwork)
library(lmtest)
library(sandwich)
library(gridExtra)
library(grid)
plan(multisession)
showtext_auto()
font_add_google("Merriweather", "latexfont")
df <- read_xlsx("~/Downloads/FarnsworthCrashData (1).xlsx")
```

```{r}
# CALCULATE ATT

# Format columns
df <- df %>%
  rename_all(tolower) %>%
  mutate(
    month_num = match(tolower(month), tolower(month.abb)),
    year = suppressWarnings(as.numeric(year))) %>%
  filter(!is.na(year), !is.na(month_num)) %>%
  mutate(
    date = make_date(year, month_num, 1),
    crash_rate = crashes / vmt)

# Set pre- and post- periods
policy_start <- as.Date("2020-11-01")
df_pre <- df %>% filter(date < policy_start)
df_post <- df %>% filter(date >= policy_start)

# Pivot wide in the pre-period to prepare for the matrix minimization problem
df_pre_wide <- df_pre %>%
  select(date, state, crash_rate) %>%
  pivot_wider(names_from = state, values_from = crash_rate, values_fn = sum)

# Set treated versus untreated states
treated_state <- "Oregon"
all_states <- setdiff(colnames(df_pre_wide), "date")
donor_states <- setdiff(all_states, treated_state)

# Set y_o as the outcome vector for the treated unit in the pre-period
y_o <- df_pre_wide[[treated_state]]

# Set Y_d as the matrix of outcome vectors for donor states in the pre-period
Y_d <- df_pre_wide[, donor_states] %>% as.matrix()

# Define function for synthetic control
scm_fit <- function(y, Y) {
  Dmat <- 2 * t(Y) %*% Y
  dvec <- 2 * t(Y) %*% y
  Amat <- cbind(rep(1, ncol(Y)), diag(ncol(Y)))
  bvec <- c(1, rep(0, ncol(Y)))
  meq <- 1
  sol <- solve.QP(Dmat, dvec, Amat, bvec, meq = meq)
  sol$solution}

# Minimize the squared error between Oregon and the donor states in the pre-period
w_hat <- scm_fit(y_o, Y_d)

# Display donor weights
weights_df <- data.frame(donor = donor_states,
  weight = round(w_hat, 4)) %>% 
  arrange(desc(weight))
  kable(weights_df, caption = "Donor Weights") %>%
  kable_styling(latex_options = c("striped", "hold_position"))

# Create synthetic Oregon from donor states and flag post-policy months
df_wide_all <- df %>%
  select(date, state, crash_rate) %>%
  pivot_wider(names_from = state, values_from = crash_rate, values_fn = sum) %>%
  mutate(synthetic = rowSums(across(all_of(donor_states), ~ .x * w_hat[which(donor_states == cur_column())])),
    post = date >= ymd("2020-11-01"))

# Apply scalar correction to match Oregon's level
c <- mean(df_wide_all$Oregon[!df_wide_all$post], na.rm = TRUE) /
     mean(df_wide_all$synthetic[!df_wide_all$post], na.rm = TRUE)

# Caclulate the estimated difference between Oregon and synthetic control at each time point
df_wide_all <- df_wide_all %>%
  mutate(
    synthetic_scaled = synthetic * c,
    gap = Oregon - synthetic_scaled)

# Compute average treatment gap before and after policy
att_summary <- df_wide_all %>%
  group_by(post) %>%
  summarise(avg_gap = mean(gap, na.rm = TRUE), .groups = "drop")

# Calculate ATT as the post-period average gap minus pre-period average gap
att <- diff(att_summary$avg_gap)
print(att)

# Calculate pre-treatment MSPE
pre_mspe <- df_wide_all %>%
  filter(!post) %>%
  summarise(
    mspe = mean((Oregon - synthetic_scaled)^2, na.rm = TRUE),
    rmse = sqrt(mspe),
    mae = mean(abs(Oregon - synthetic_scaled), na.rm = TRUE))

# Create a table to display the pre-treatment fit metrics
fit_metrics_table <- tibble(
  Metric = c("Mean Squared Prediction Error (MSPE)", 
             "Root Mean Squared Error (RMSE)",
             "Mean Absolute Error (MAE)"),
  Value = c(round(pre_mspe$mspe, 6), round(pre_mspe$rmse, 6), round(pre_mspe$mae, 6)))

kable(fit_metrics_table, caption = "Pre-Treatment Fit Quality Metrics") %>%
kable_styling(latex_options = c("striped", "hold_position"))
```

```{r}
# PLACEBO TESTS

# Create storage for placebo ATT estimates
placebo_att <- c()

# Loop through each donor state and treat it as if it were "treated"
for (state in donor_states) {

# Construct synthetic control for placebo state
y_placebo <- df_pre_wide[[state]]
Y_d_placebo <- df_pre_wide[, setdiff(donor_states, state)] %>% as.matrix()

# Estimate weights using earlier function
w_placebo <- tryCatch({
    scm_fit(y_placebo, Y_d_placebo)
  }, error = function(e) return(NULL))

# Create synthetic control for placebo-treated state
if (!is.null(w_placebo)) {
  synth_placebo <- as.matrix(df_wide_all[, setdiff(donor_states, state)]) %*% w_placebo
  gap_placebo <- df_wide_all[[state]] - synth_placebo
  post_period <- df_wide_all$date >= as.Date("2020-11-01")
    
# Compute placebo ATT and store it
  placebo_ATT <- mean(gap_placebo[post_period], na.rm = TRUE)
  placebo_att <- c(placebo_att, placebo_ATT)}}

# Compute p-value by calculating share of placebo ATTs as extreme as Oregon's
placebo_p_value <- mean(abs(placebo_att) >= abs(att))

# Compute standard error using standard deviation of placebo ATTs
se_placebo <- sd(placebo_att, na.rm = TRUE)

print(placebo_p_value)
print(se_placebo)

# Compute pre- and post-treatment MSPEs for Oregon
oregon_pre_mspe <- mean((df_wide_all$Oregon[!df_wide_all$post] - 
                        df_wide_all$synthetic_scaled[!df_wide_all$post])^2, na.rm = TRUE)
oregon_post_mspe <- mean((df_wide_all$Oregon[df_wide_all$post] - 
                         df_wide_all$synthetic_scaled[df_wide_all$post])^2, na.rm = TRUE)
oregon_mspe_ratio <- oregon_post_mspe / oregon_pre_mspe

# Calculate MSPE ratios for all placebo states
placebo_mspe_ratios <- c()
placebo_pre_mspes <- c()
state_names <- c()

# Repeat synthetic control estimation for each placebo
for (state in donor_states) {
  y_placebo <- df_pre_wide[[state]]
  Y_d_placebo <- df_pre_wide[, setdiff(donor_states, state)] %>% as.matrix()
  
  w_placebo <- tryCatch({
    scm_fit(y_placebo, Y_d_placebo)
  }, error = function(e) return(NULL))
  
  if (!is.null(w_placebo)) {
    synth_placebo <- as.matrix(df_wide_all[, setdiff(donor_states, state)]) %*% w_placebo
    
# Compute pre- and post-MSPEs
    pre_mspe <- mean((df_wide_all[[state]][!df_wide_all$post] - 
                      synth_placebo[!df_wide_all$post])^2, na.rm = TRUE)
    post_mspe <- mean((df_wide_all[[state]][df_wide_all$post] - 
                       synth_placebo[df_wide_all$post])^2, na.rm = TRUE)

# Store MSPE ratio if valid  
    if (pre_mspe > 0) {
      mspe_ratio <- post_mspe / pre_mspe
      placebo_mspe_ratios <- c(placebo_mspe_ratios, mspe_ratio)
      placebo_pre_mspes <- c(placebo_pre_mspes, pre_mspe)
      state_names <- c(state_names, state)}}}

# Create MSPE ratio comparison table
mspe_ratio_df <- data.frame(
  State = c("Oregon", state_names),
  Pre_MSPE = c(oregon_pre_mspe, placebo_pre_mspes),
  MSPE_Ratio = c(oregon_mspe_ratio, placebo_mspe_ratios)) %>% 
  arrange(desc(MSPE_Ratio))

# Display MSPE ratio table and Oregon's implied p-value
kable(mspe_ratio_df, caption = "MSPE Ratio Comparison (Post/Pre)") %>%
kable_styling(latex_options = c("striped", "hold_position"))
```

```{r}
# CREATE PLOT

# Prepare plot data by selecting Oregon and synthetic control crash rates, reshaping to long format
df_plot <- df_wide_all %>%
  select(date, Oregon, synthetic_scaled) %>%
  pivot_longer(cols = c("Oregon", "synthetic_scaled"), names_to = "series", values_to = "crash_rate") %>%
  filter(!is.na(crash_rate)) %>%
  group_by(series) %>%
  mutate(smoothed_rate = zoo::rollmean(crash_rate, k = 3, fill = NA, align = "center")) %>%
  ungroup() %>%
  mutate(series = recode(series, synthetic_scaled = "Synthetic Control"))

# Plot crash rates over time with treatment date and shaded post-treatment region
ggplot(df_plot, aes(x = date, y = smoothed_rate, color = series)) +
  annotate("rect", xmin = as.Date("2020-11-01"), xmax = max(df_plot$date),
           ymin = -Inf, ymax = Inf, fill = "gray90", alpha = 0.7) +
  geom_line(size = 0.9) +
  geom_vline(xintercept = as.Date("2020-11-01"), linetype = "dashed") +
  annotate("text", x = as.Date("2020-11-01"),
           y = max(df_plot$smoothed_rate, na.rm = TRUE),
           label = "Measure 110", angle = 90, vjust = -0.5, hjust = 1.1,
           size = 3.5, family = "latexfont") +
  scale_y_continuous(name = "Crashes per Million VMT") +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_color_manual(values = c("Oregon" = "#1b9e77", "Synthetic Control" = "#003366")) +
  labs(x = "Year", color = "Group") +
  theme_minimal(base_family = "latexfont") +
  theme(
    axis.title.x = element_text(margin = margin(t = 10)),
    axis.title.y = element_text(margin = margin(r = 10)),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
  )

# Save file to folder
ggsave("images/synthdid_plot_scaled.pdf", width = 8, height = 4, dpi = 300)
```

```{r}
# SENSITIVITY ANALYSIS

# Define donor subsets
subset_list <- list(
  Neighbors          = c("Washington", "Idaho", "California"),
  Exclude_Washington = setdiff(donor_states, "Washington"))

# Prepare storage
subset_results <- list()
weights_by_subset <- list()
se_by_subset <- list()
pval_by_subset <- list()

# Loop over each donor subset
for (label in names(subset_list)) {
  donors_subset <- subset_list[[label]]
  y_oregon <- df_pre_wide$Oregon
  Y_subset <- df_pre_wide[, donors_subset] %>% as.matrix()
  w_subset <- tryCatch(scm_fit(y_oregon, Y_subset), error = function(e) NULL)
  if (is.null(w_subset)) next
  
# Construct synthetic series and gap
  synth_all   <- as.matrix(df_wide_all[, donors_subset]) %*% w_subset
  gap         <- df_wide_all$Oregon - synth_all
  post_period <- df_wide_all$date >= as.Date("2020-11-01")
  
# Compute raw ATT
  ATT_raw <- mean(gap[post_period], na.rm = TRUE)
  
# compute placebo ATTs for the subset
  placebo_ATT_subset <- c()
  for (pseudo_treated in donors_subset) {
    Y_pseudo <- df_pre_wide[, setdiff(donors_subset, pseudo_treated)] %>% as.matrix()
    w_pseudo <- tryCatch(scm_fit(df_pre_wide[[pseudo_treated]], Y_pseudo),
                         error = function(e) NULL)
    if (is.null(w_pseudo)) next
    synth_pseudo <- as.matrix(df_wide_all[, setdiff(donors_subset, pseudo_treated)]) %*% w_pseudo
    gap_pseudo   <- df_wide_all[[pseudo_treated]] - synth_pseudo
    placebo_ATT_subset <- c(placebo_ATT_subset,
                            mean(gap_pseudo[post_period], na.rm = TRUE))}
  
# Correct ATT bias 
  bias_subset <- mean(placebo_ATT_subset, na.rm = TRUE)
  ATT_corrected_subset <- ATT_raw - bias_subset
  se_corrected_subset <- sd(placebo_ATT_subset - bias_subset, na.rm = TRUE)
  pval_corrected_subset <- mean(
    abs(placebo_ATT_subset - bias_subset) >= abs(ATT_corrected_subset),
    na.rm = TRUE)
  
# Store results
  subset_results[[label]] <- ATT_corrected_subset
  weights_by_subset[[label]] <- setNames(round(w_subset, 4), donors_subset)
  se_by_subset[[label]] <- se_corrected_subset
  pval_by_subset[[label]] <- pval_corrected_subset}

# Combine into tables
subset_df <- tibble(
  Subset           = names(subset_results),
  ATT_Estimate     = unlist(subset_results),
  Std_Error        = unlist(se_by_subset),
  Empirical_p_value= unlist(pval_by_subset))

weight_long <- bind_rows(
  lapply(names(weights_by_subset), function(label) {
    tibble(
      Subset = label,
      Donor  = names(weights_by_subset[[label]]),
      Weight = weights_by_subset[[label]])}))

# Display
kable(subset_df, caption = "Bias-Corrected Sensitivity Analysis by Donor Subset") %>%
  kable_styling("striped", "hover")

kable(weight_long, caption = "Donor Weights by Subset") %>%
  kable_styling("striped", "hover")
```


```{r}
# SENSITIVITY ANALYSIS

# Define three donor subsets
subset_list <- list(
  Neighbors = c("Washington", "Idaho", "California"),
  Western_LowCrash = c("Washington", "Idaho", "Utah", "Colorado"),
  Exclude_Washington = setdiff(donor_states, "Washington"))

# Create empty lists to store results by subset
  subset_results <- list()
  weights_by_subset <- list()
  se_by_subset <- list()
  pval_by_subset <- list()
  synth_series <- list()
  bias_corrected_results <- list()

# Loop over each donor subset
  for (label in names(subset_list)) {
    donors_subset <- subset_list[[label]]

# Reconstruct synthetic control for Oregon using the subset
  y_oregon <- df_pre_wide$Oregon
  Y_subset <- df_pre_wide[, donors_subset] %>% as.matrix()

# Estimate weights using earlier function
  w_subset <- tryCatch({
  scm_fit(y_oregon, Y_subset)}, error = function(e) return(NULL))

# Create synthetic control using subset
  if (!is.null(w_subset)) {
    synth_all <- as.matrix(df_wide_all[, donors_subset]) %*% w_subset
    gap <- df_wide_all$Oregon - synth_all
    post_period <- df_wide_all$date >= as.Date("2020-11-01")

# Calculate ATT from the subset
    ATT_subset <- mean(gap[post_period], na.rm = TRUE)

# Calculate SE for each estimate using placebos
    
# Create empty vector to store placebo ATTs
    placebo_ATT_subset <- c()
    
# Loop over each donor subset
    for (pseudo_treated in donors_subset) {
      y_pseudo <- df_pre_wide[[pseudo_treated]]
      Y_pseudo <- df_pre_wide[, setdiff(donors_subset, pseudo_treated)] %>% as.matrix()

# Estimate weights using earlier function
      w_pseudo <- tryCatch({
        scm_fit(y_pseudo, Y_pseudo)
      }, error = function(e) NULL)

# Create synthetic control for placebo-treated state
      if (!is.null(w_pseudo)) {
        synth_pseudo <- as.matrix(df_wide_all[, setdiff(donors_subset, pseudo_treated)]) %*% w_pseudo
        gap_pseudo <- df_wide_all[[pseudo_treated]] - synth_pseudo
        post_period <- df_wide_all$date >= as.Date("2020-11-01")

# Calculate placebo ATT for each state in subset
        placebo_att <- mean(gap_pseudo[post_period], na.rm = TRUE)
        placebo_ATT_subset <- c(placebo_ATT_subset, placebo_att)}}

# Bias correction and placebo inference
  placebo_bias <- mean(placebo_ATT_subset, na.rm = TRUE)
  ATT_bias_corrected <- ATT_subset - placebo_bias
  se_placebo_subset <- sd(placebo_ATT_subset, na.rm = TRUE)
  pval_placebo_subset <- mean(abs(placebo_ATT_subset) >= abs(ATT_bias_corrected))

# Store results
  subset_results[[label]] <- ATT_subset
  bias_corrected_results[[label]] <- ATT_bias_corrected
  weights_by_subset[[label]] <- round(setNames(w_subset, donors_subset), 4)
  se_by_subset[[label]] <- se_placebo_subset
    pval_by_subset[[label]] <- pval_placebo_subset}}
  # Final safety-filtered table construction
valid_labels <- names(subset_results)

# Initialize safe containers
att_raw_vec <- numeric()
att_bias_vec <- numeric()
se_vec <- numeric()
pval_vec <- numeric()

# Loop through valid labels manually and extract cleanly
for (label in valid_labels) {
  att_raw <- as.numeric(subset_results[[label]])
  att_bias <- as.numeric(bias_corrected_results[[label]])
  se <- as.numeric(se_by_subset[[label]])
  pval <- as.numeric(pval_by_subset[[label]])
  
  if (length(att_raw) == 1 && !is.na(att_raw) &&
      length(att_bias) == 1 && !is.na(att_bias) &&
      length(se) == 1 && !is.na(se) &&
      length(pval) == 1 && !is.na(pval)) {
    
    att_raw_vec <- c(att_raw_vec, att_raw)
    att_bias_vec <- c(att_bias_vec, att_bias)
    se_vec <- c(se_vec, se)
    pval_vec <- c(pval_vec, pval)
  }
}

# Build final data frame
subset_df <- data.frame(
  Subset = valid_labels[seq_along(att_raw_vec)],
  ATT_Raw = round(att_raw_vec, 4),
  ATT_Bias_Corrected = round(att_bias_vec, 4),
  Std_Error = round(se_vec, 4),
  Empirical_p_value = round(pval_vec, 4)
)

# Reshape donor weights into long format for viewing
weight_long <- do.call(rbind, lapply(names(weights_by_subset), function(nm) {
  data.frame(
    Subset = nm,
    Donor = names(weights_by_subset[[nm]]),
    Weight = unname(weights_by_subset[[nm]]))}))

# Show ATT estimates and placebo-based inference for each subset
kable(subset_df, caption = "Sensitivity Analysis by Donor Subset (Placebo-Based SE and p-values)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Show synthetic weights assigned to each donor in each subset
kable(weight_long, caption = "Donor Weights by Subset") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

```{r}
# PSEUDO-TREATMENT TEST

# Set seed so the results of the sampling can be reproduced
set.seed(1066)

# Set cutoff for pseudo-treatment dates after 2015 so we have at least two years to create a synthetic control
pseudo_periods <- df_pre$date[df_pre$date >= as.Date("2015-01-01")]
n_placebo_draws <- 50  

# Loop over each pseudo-treatment date and estimate synthetic control gaps
pseudo_results_nested <- future_lapply(pseudo_periods, function(pseudo_date) {
  
# Filter training data before the pseudo-treatment date
  df_train <- df_pre %>% filter(date < pseudo_date)
  
# Pivot training data to wide format
  df_train_wide <- df_train %>%
    select(date, state, crash_rate) %>%
    pivot_wider(names_from = state, values_from = crash_rate, values_fn = sum)
  if (nrow(df_train_wide) <= 2) {
    return(list(ATT = NA, SE = NA, p_value = NA))}
  
# Construct synthetic Oregon from pre-pseudo data
  y_oregon <- df_train_wide$Oregon
  Y_d_oregon <- df_train_wide[, donor_states] %>% as.matrix()

# Estimate weights using earlier function
  w_hat_oregon <- tryCatch({
    scm_fit(y_oregon, Y_d_oregon)
  }, error = function(e) NULL)
  
# Transform dataset to apply synthetic control across full period
  df_all_wide <- df_pre %>%
    select(date, state, crash_rate) %>%
    pivot_wider(names_from = state, values_from = crash_rate, values_fn = sum)

# Create synthetic control before pseudo-treatment date
  synthetic_series_oregon <- rowSums(as.matrix(df_all_wide[, donor_states]) *
                                   matrix(rep(w_hat_oregon, each = nrow(df_all_wide)), ncol = length(donor_states)))

# Scale so fake synthetic control matches fake treated unit 
scalar_oregon <- mean(df_all_wide$Oregon[!df_all_wide$date >= pseudo_date], na.rm = TRUE) /
                 mean(synthetic_series_oregon[!df_all_wide$date >= pseudo_date], na.rm = TRUE)
synthetic_series_oregon_scaled <- synthetic_series_oregon * scalar_oregon

# Compute the gap between actual and synthetic Oregon
df_all_wide <- df_all_wide %>%
  mutate(
    synthetic_pseudo = synthetic_series_oregon_scaled,
    gap_pseudo = Oregon - synthetic_pseudo,
    post_pseudo = date >= pseudo_date)

# Compute pseudo ATT
  att_summary_pseudo <- df_all_wide %>%
    group_by(post_pseudo) %>%
    summarise(
      avg_gap = mean(gap_pseudo, na.rm = TRUE),
      .groups = "drop")
  if (nrow(att_summary_pseudo) != 2) {
    return(list(ATT = NA, SE = NA, p_value = NA))}
  
  att_oregon <- diff(att_summary_pseudo$avg_gap)
  
# Calculate SEs for pseudo treatment estimates using placebo-based inference

# Create empty vector to store placebo ATTs
  placebo_att_list <- c()

# Loop over each donor state
  for (draw in 1:n_placebo_draws) {
    fake_treated <- sample(donor_states, 1)

# Construct synthetic control for placebo state
    Y_d_fake <- df_train_wide[, setdiff(donor_states, fake_treated)] %>% as.matrix()
    y_fake <- df_train_wide[[fake_treated]]

# Estimate weights using earlier function
  w_hat_fake <- tryCatch({
    scm_fit(y_fake, Y_d_fake)
  }, error = function(e) NULL)

# Create synthetic control for placebo-treated state
  synthetic_series_fake <- rowSums(as.matrix(df_all_wide[, setdiff(donor_states, fake_treated)]) *
    matrix(rep(w_hat_fake, each = nrow(df_all_wide)), ncol = length(setdiff(donor_states, fake_treated))))
      
# Scale each placebo's synthetic control to match its own pre-period mean
  post_fake <- df_all_wide$date >= pseudo_date
  scalar_fake <- mean(df_all_wide[[fake_treated]][!post_fake], na.rm = TRUE) /
               mean(synthetic_series_fake[!post_fake], na.rm = TRUE)
  synthetic_series_fake_scaled <- synthetic_series_fake * scalar_fake

# Compute and store placebo ATT for this draw
  gap_fake <- df_all_wide[[fake_treated]] - synthetic_series_fake_scaled
  placebo_ATT <- mean(gap_fake[post_fake], na.rm = TRUE) - mean(gap_fake[!post_fake], na.rm = TRUE)
  placebo_att_list <- c(placebo_att_list, placebo_ATT)}

# Compute SE using distribution of placebo estimates
  se_pseudo <- sd(placebo_att_list, na.rm = TRUE)
  if (!is.na(att_oregon) & !is.na(se_pseudo) & se_pseudo > 0) {
    z_val <- att_oregon / se_pseudo
    p_val <- 2 * pnorm(-abs(z_val))
  } else {
    p_val <- NA}
  
# Return ATT, SE, and p-value as list for this pseudo-treatment period
  list(ATT = att_oregon, SE = se_pseudo, p_value = p_val)
}, future.seed = TRUE)

# Merge results across all pseudo-treatment dates into a dataframe
pseudo_results_nested_df <- data.frame(
  Pseudo_Treatment_Date = pseudo_periods,
  ATT = sapply(pseudo_results_nested, `[[`, "ATT"),
  SE = sapply(pseudo_results_nested, `[[`, "SE"),
  p_value = sapply(pseudo_results_nested, `[[`, "p_value"))

# Correct ATT's bias
bias_estimate <- mean(pseudo_results_nested_df$ATT, na.rm = TRUE)
att_bias_corrected <- att - bias_estimate
print(bias_estimate)
print(att_bias_corrected)

# Display results
kable(pseudo_results_nested_df, caption = "Nested Parallel Pseudo-Treatment Test Results") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Keep only one pseudo-treatment per month to prevent overplotting
pseudo_results_filtered <- pseudo_results_nested_df %>%
  mutate(month = lubridate::floor_date(Pseudo_Treatment_Date, "3 months")) %>%
  group_by(month) %>%
  slice(1) %>%
  ungroup()

# Plot pseudo-treatment ATT over time
ggplot(pseudo_results_filtered, aes(x = month, y = ATT)) +
  geom_errorbar(aes(ymin = ATT - 1.96 * SE, ymax = ATT + 1.96 * SE), width = 20, color = "black") +
  geom_point(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = att_bias_corrected, color = "red", linetype = "solid") +
  scale_x_date(
    date_breaks = "1 year",
    date_labels = "%Y") +
  labs(
    x = "Pseudo-Treatment Date",
    y = "Estimated ATT") +
  theme_minimal(base_family = "latexfont") +
  theme(axis.title.x = element_text(margin = margin(t = 15)))

# Report the proportion of pseudo-treatments with p < 0.05
n_significant_nested <- sum(pseudo_results_nested_df$p_value < 0.05, na.rm = TRUE)
n_total_nested <- nrow(pseudo_results_nested_df)
cat("\nOut of", n_total_nested, "pseudo-treatments,", n_significant_nested, 
    "had p < 0.05 (", round(100 * n_significant_nested/n_total_nested, 2), "% ).\n")

# Save file to folder
ggsave("images/pseudo_treatment.pdf", width = 8, height = 4, dpi = 300)
```

```{r}
# Define the real treatment result
true_treatment_date <- as.Date("2021-02-01")
att_or <- -0.083
se_or <- 0.371

# Append Oregon result to filtered pseudo results
pseudo_results_filtered <- pseudo_results_filtered %>%
  mutate(is_real = FALSE) %>%
  bind_rows(
    data.frame(
      month = true_treatment_date,
      ATT = att_or,
      SE = se_or,
      is_real = TRUE))

# Plot pseudo-treatment ATT over time
ggplot(pseudo_results_filtered, aes(x = month, y = ATT, color = is_real)) +
  geom_errorbar(aes(ymin = ATT - 1.96 * SE, ymax = ATT + 1.96 * SE), width = 20, color = "black") +
  geom_point(size = 2.5) +
  scale_color_manual(
    values = c("FALSE" = "blue", "TRUE" = "red"),
    labels = c("FALSE" = "Fake Treatments", "TRUE" = "Measure 110"),
    name = NULL 
  ) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  labs(
    x = "Pseudo-Treatment Date",
    y = "Estimated ATT",
  ) +
  theme_minimal(base_family = "latexfont") +
  theme(
    axis.title.x = element_text(margin = margin(t = 15)),
    legend.position = "right"  # you can also try "top", "bottom", or "left"
    )

# Report the proportion of pseudo-treatments with p < 0.05
n_significant_nested <- sum(pseudo_results_nested_df$p_value < 0.05, na.rm = TRUE)
n_total_nested <- nrow(pseudo_results_nested_df)
cat("\nOut of", n_total_nested, "pseudo-treatments,", n_significant_nested, 
    "had p < 0.05 (", round(100 * n_significant_nested/n_total_nested, 2), "% ).\n")

# Save file to folder
ggsave("images/pseudo_treatment.pdf", width = 8, height = 4, dpi = 300)
```
```{r}
# Compute average placebo ATT (drift)
bias_drift <- mean(pseudo_results_filtered$ATT[!pseudo_results_filtered$is_real], na.rm = TRUE)

# Apply correction to ATT and compute new y-axis values
pseudo_results_filtered <- pseudo_results_filtered %>%
  mutate(
    ATT_corrected = ATT - bias_drift,
    ymin_corrected = ATT_corrected - 1.96 * SE,
    ymax_corrected = ATT_corrected + 1.96 * SE
  )

# Plot pseudo-treatment ATT over time
ggplot(pseudo_results_filtered, aes(x = month, y = ATT_corrected, color = is_real)) +
  geom_errorbar(aes(ymin = ymin_corrected, ymax = ymax_corrected), width = 20, color = "black") +
  geom_point(size = 2.5) +
  scale_color_manual(
    values = c("FALSE" = "blue", "TRUE" = "red"),
    labels = c("FALSE" = "Fake Treatments", "TRUE" = "Measure 110"),
    name = NULL
  ) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  labs(
    x = "Pseudo-Treatment Date",
    y = "Bias-Corrected ATT",
  ) +
  theme_minimal(base_family = "latexfont") +
  theme(
    axis.title.x = element_text(margin = margin(t = 15)),
    legend.position = "right"
  )

# Report the proportion of pseudo-treatments with p < 0.05
n_significant_nested <- sum(pseudo_results_nested_df$p_value < 0.05, na.rm = TRUE)
n_total_nested <- nrow(pseudo_results_nested_df)
cat("\nOut of", n_total_nested, "pseudo-treatments,", n_significant_nested, 
    "had p < 0.05 (", round(100 * n_significant_nested/n_total_nested, 2), "% ).\n")

# Save file to folder
ggsave("images/pseudo_treatment_bias_corrected.pdf", width = 8, height = 4, dpi = 300)
```


```{r}
# REGRESSION ESTIMATE

# Run DID regression
lm.DID <- lm(crash_rate ~ treated * post + vmt + pop_density + factor(month_num), data = df)
clustered_se <- vcovCL(model_covariates, cluster = ~state)
coeftest(model_covariates, vcov = clustered_se)
```

```{r}
# Compute shared y-axis limits
df_ca <- df_wide_all %>% select(date, Oregon, California)
df_wy <- df_wide_all %>% select(date, Oregon, Wyoming)
df_wa <- df_wide_all %>% select(date, Oregon, Washington)

smooth_df <- function(df, other) {
  df %>%
    rename(Other = !!sym(other)) %>%
    pivot_longer(c("Oregon","Other"), names_to="series", values_to="crash_rate") %>%
    group_by(series) %>%
    mutate(smoothed_rate = zoo::rollmean(crash_rate, 3, fill=NA, align="center")) %>%
    ungroup()}

sm_ca <- smooth_df(df_ca, "California")
sm_wy <- smooth_df(df_wy, "Wyoming")
sm_wa <- smooth_df(df_wa, "Washington")

global_ylim <- range(
  c(sm_ca$smoothed_rate, sm_wy$smoothed_rate, sm_wa$smoothed_rate),
  na.rm = TRUE)
```

```{r}
# Oregon vs. California
ggplot(sm_ca, aes(date, smoothed_rate, color = series)) +
  annotate("rect",
    xmin = as.Date("2020-11-01"), xmax = max(sm_ca$date),
    ymin = -Inf, ymax = Inf, fill = "gray90", alpha = 0.7
  ) +
  geom_line(size = 0.9) +
  geom_vline(xintercept = as.Date("2020-11-01"), linetype = "dashed") +
  annotate("text",
    x = as.Date("2020-11-01"), y = global_ylim[2],
    label = "Measure 110", angle = 90, vjust = -0.5, hjust = 1.1,
    size = 3.5, family = "latexfont"
  ) +
  scale_y_continuous("Crashes per Million VMT", limits = global_ylim) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_color_manual(
    values = c("Oregon" = "#1b9e77", "Other" = "#d95f02"),
    labels = c("Oregon", "California", color = "State")
  ) +
  labs(x = "Year", color = "State") +
  theme_minimal(base_family = "latexfont") +
  theme(legend.position = "right",
        axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

ggsave("images/Oregon_vs_California.pdf", width = 6, height = 4, dpi = 300)
```

```{r}
# Oregon vs. Wyoming
ggplot(sm_wy, aes(date, smoothed_rate, color = series)) +
  annotate("rect",
    xmin = as.Date("2020-11-01"), xmax = max(sm_wy$date),
    ymin = -Inf, ymax = Inf, fill = "gray90", alpha = 0.7
  ) +
  geom_line(size = 0.9) +
  geom_vline(xintercept = as.Date("2020-11-01"), linetype = "dashed") +
  annotate("text",
    x = as.Date("2020-11-01"), y = global_ylim[2],
    label = "Measure 110", angle = 90, vjust = -0.5, hjust = 1.1,
    size = 3.5, family = "latexfont"
  ) +
  scale_y_continuous("Crashes per Million VMT", limits = global_ylim) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_color_manual(
    values = c("Oregon" = "#1b9e77", "Other" = "#800000"),
    labels = c("Oregon", "Wyoming", color = "State")
  ) +
  labs(x = "Year", color = "State") +
  theme_minimal(base_family = "latexfont") +
  theme(legend.position = "right",
        axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)),
  plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))

ggsave("images/Oregon_vs_Wyoming.pdf", width = 6, height = 4, dpi = 300)
```

```{r}
# Oregon vs. Washington
ggplot(sm_wa, aes(date, smoothed_rate, color = series)) +
  annotate("rect",
    xmin = as.Date("2020-11-01"), xmax = max(sm_wa$date),
    ymin = -Inf, ymax = Inf, fill = "gray90", alpha = 0.7
  ) +
  geom_line(size = 0.9) +
  geom_vline(xintercept = as.Date("2020-11-01"), linetype = "dashed") +
  annotate("text",
    x = as.Date("2020-11-01"), y = global_ylim[2],
    label = "Measure 110", angle = 90, vjust = -0.5, hjust = 1.1,
    size = 3.5, family = "latexfont"
  ) +
  scale_y_continuous("Crashes per Million VMT", limits = global_ylim) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_color_manual(
    values = c("Oregon" = "#1b9e77", "Other" = "#800080"),
    labels = c("Oregon", "Washington", color = "State")
  ) +
  labs(x = "Year", color = "State") +
  theme_minimal(base_family = "latexfont") +
  theme(legend.position = "right",
        axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

ggsave("images/Oregon_vs_Washington.pdf", width = 6, height = 4, dpi = 300)
```

```{r}
# REGRESSION ESTIMATE

# Run DID regression
lm.DID <- lm(crash_rate ~ treated * post + vmt + factor(month_num), data = df)
clustered_se <- vcovCL(model_covariates, cluster = ~state)
coeftest(model_covariates, vcov = clustered_se)
```

```{r}
# PLOT PLACEBO DISTRIBUTION AGAINST BIAS CORRECT ATT

# Extract placebo ATTs
placebo_atts <- na.omit(pseudo_results_nested_df$ATT)

# Estimate bias
bias_estimate <- mean(placebo_atts)
att_bias_corrected <- att_oregon_actual - bias_estimate

# Calculate test p-value
p_value <- mean(abs(shifted_placebos) >= abs(att_bias_corrected))

# Create data frame for the histogram
placebo_df <- data.frame(value = shifted_placebos)
  hist_counts <- hist(shifted_placebos, plot = FALSE, breaks = seq(
  min(shifted_placebos) - bin_width,
  max(shifted_placebos) + bin_width,
  by = bin_width
))$counts
  
bin_width <- 0.01 
n_placebos <- nrow(placebo_df)

# Create theme
publication_theme <- theme_minimal() +
  theme(
    text = element_text(family = "latexfont", color = "black"),
    plot.title = element_text(size = 11, face = "bold", hjust = 0),
    plot.subtitle = element_text(size = 10, hjust = 0, margin = margin(b = 15)),
    axis.title.x = element_text(size = 10, margin = margin(t = 10)),
    axis.title.y = element_text(size = 10, margin = margin(r = 10)), 
    axis.text = element_text(size = 9, color = "black"),
    legend.position = "none",
    panel.grid.major = element_line(color = "gray90"),
    panel.grid.minor = element_line(color = "gray95"),
    plot.margin = margin(20, 20, 20, 20),
    plot.caption = element_text(size = 8, hjust = 0, margin = margin(t = 15)),
    panel.border = element_blank(),
    axis.line = element_line(color = "black", size = 0.5))

# Create the histogram
main_plot <- ggplot(placebo_df, aes(x = value)) +
  geom_histogram(
    binwidth = 0.01,
    fill = "gray80",
    color = "gray20",
    alpha = 0.7) +
  geom_density(
    aes(y = ..density.. * n_placebos * bin_width),
    color = "darkblue",
    size = 1.2,
    adjust = 1.7) +
  
# Oregon's ATT
  geom_vline(
    xintercept = att_bias_corrected - 0.0025,
    color = "red3",
    linetype = "solid",
    size = 0.9) +

# Labels
  annotate("text",
    x = att_bias_corrected,
    y = max(hist_counts) * 0.95,
  label = "Oregon ATT", color = "red3", size = 3.2, hjust = 0, family = "latexfont") +
  labs(
    x = "Placebo ATT Estimates (Bias-Corrected)",
    y = "Frequency") +
  
# Style plot
  publication_theme +
  scale_x_continuous(
    expand = c(0.02, 0.02),
    breaks = scales::pretty_breaks(n = 8)) +
  scale_y_continuous(
    expand = c(0, 0.1),
    breaks = scales::pretty_breaks(n = 6))
  coord_cartesian(ylim = c(0, 200)) 
  
# Create data for inset plot
effects_df <- data.frame(
  type = factor(c("Raw", "Bias-Corrected"), levels = c("Raw", "Bias-Corrected")),
  value = c(att_oregon_actual, att_bias_corrected))

# Create inset plot
inset_plot <- ggplot(effects_df, aes(x = type, y = value, fill = type)) +
  geom_bar(stat = "identity", width = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.3) +
  geom_text(
    aes(label = sprintf("%.3f", value)),
    position = position_dodge(width = 0.7),
    vjust = ifelse(effects_df$value < 0, 1.5, -0.5),
    size = 3) +
  scale_fill_manual(values = c("darkgreen", "darkblue")) +
  labs(
    title = "Raw vs. Corrected Effect",
    y = "Effect Size",
    x = NULL) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(size = 8, margin = margin(r = 10)),
    axis.text.y = element_text(size = 8, margin = margin(t = 20)), ,  
    axis.title = element_text(size = 9),
    plot.title = element_text(size = 10),
    panel.grid.major.x = element_blank(),
    panel.grid.minor = element_blank())

# Create final plot
final_plot <- main_plot
final_plot_with_inset <- 
  main_plot +
    inset_element(
      inset_plot,
      left   = 0.60,   # fraction of panel width
      bottom = 0.60,   # fraction of panel height
      right  = 0.98,
      top    = 0.98) +
  plot_annotation(
    title = "Distribution of Placebo Treatment Effects\nwith Raw vs. Corrected ATT Inset")

ggsave("images/synthetic_did_results.pdf", plot = final_plot, width = 7, height = 5, dpi = 300)
print(final_plot)
```

